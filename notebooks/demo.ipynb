{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç LSTM Autoencoder Anomaly Detection\n",
        "\n",
        "This notebook demonstrates time series anomaly detection using LSTM Autoencoders.\n",
        "\n",
        "## Contents\n",
        "1. Data Generation & Preparation\n",
        "2. Model Training\n",
        "3. Anomaly Detection\n",
        "4. Visualization & Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src import (\n",
        "    LSTMAutoencoder,\n",
        "    Trainer,\n",
        "    AnomalyDetector,\n",
        "    DataPreprocessor,\n",
        "    AnomalyVisualizer,\n",
        "    TimeSeriesGenerator,\n",
        "    ThresholdMethod\n",
        ")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('‚úì Modules loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic taxi ride data with anomalies\n",
        "generator = TimeSeriesGenerator(seed=42)\n",
        "data, injected_anomalies = generator.generate_taxi_data(\n",
        "    n_points=5000,\n",
        "    anomaly_ratio=0.02\n",
        ")\n",
        "\n",
        "print(f\"Generated {len(data)} data points\")\n",
        "print(f\"Injected {len(injected_anomalies)} anomaly windows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize raw data\n",
        "plt.figure(figsize=(14, 4))\n",
        "plt.plot(data, linewidth=0.8)\n",
        "plt.xlabel('Time (hours)')\n",
        "plt.ylabel('Taxi Rides')\n",
        "plt.title('Synthetic Taxi Ride Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale data\n",
        "preprocessor = DataPreprocessor(scaler_type='minmax')\n",
        "data_scaled = preprocessor.fit_transform(data)\n",
        "\n",
        "# Create sequences\n",
        "SEQ_LENGTH = 50\n",
        "sequences = DataPreprocessor.create_sequences(data_scaled, seq_length=SEQ_LENGTH)\n",
        "\n",
        "print(f\"Sequence shape: {sequences.shape}\")\n",
        "print(f\"  - {sequences.shape[0]} samples\")\n",
        "print(f\"  - {sequences.shape[1]} timesteps per sample\")\n",
        "print(f\"  - {sequences.shape[2]} features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into train/test\n",
        "train_size = int(0.8 * len(sequences))\n",
        "train_data = sequences[:train_size]\n",
        "test_data = sequences[train_size:]\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create & Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create LSTM Autoencoder\n",
        "model = LSTMAutoencoder(\n",
        "    input_size=1,\n",
        "    hidden_size=32,\n",
        "    num_layers=1\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "trainer = Trainer(model, learning_rate=0.001)\n",
        "\n",
        "history = trainer.fit(\n",
        "    train_data,\n",
        "    val_data=test_data,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    early_stopping_patience=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "viz = AnomalyVisualizer()\n",
        "viz.plot_training_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Detect Anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize detector\n",
        "detector = AnomalyDetector(model)\n",
        "\n",
        "# Fit threshold on training data (normal patterns)\n",
        "detector.fit(train_data, method=ThresholdMethod.MEAN_STD, n_std=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect anomalies in test data\n",
        "results = detector.detect(test_data)\n",
        "\n",
        "print(f\"\\nüìä Detection Results:\")\n",
        "print(f\"   Total samples: {len(test_data)}\")\n",
        "print(f\"   Anomalies found: {results.is_anomaly.sum()}\")\n",
        "print(f\"   Anomaly ratio: {results.anomaly_ratio:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot anomaly scores\n",
        "viz.plot_anomaly_scores(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot error distribution\n",
        "viz.plot_error_distribution(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get test data as flat array for visualization\n",
        "test_flat = test_data[:, -1, 0]  # Last timestep of each sequence\n",
        "\n",
        "# Plot time series with anomalies\n",
        "viz.plot_time_series_with_anomalies(\n",
        "    test_flat,\n",
        "    results,\n",
        "    title='Test Data with Detected Anomalies'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive dashboard\n",
        "viz.create_dashboard(\n",
        "    test_flat,\n",
        "    results,\n",
        "    history,\n",
        "    save_path='../output/dashboard.png'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compare Threshold Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different threshold methods\n",
        "methods = [\n",
        "    (ThresholdMethod.MEAN_STD, {'n_std': 2}),\n",
        "    (ThresholdMethod.MEAN_STD, {'n_std': 3}),\n",
        "    (ThresholdMethod.PERCENTILE, {'percentile': 95}),\n",
        "    (ThresholdMethod.IQR, {'k': 1.5}),\n",
        "]\n",
        "\n",
        "print(\"Threshold Method Comparison:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for method, params in methods:\n",
        "    detector.fit(train_data, method=method, **params)\n",
        "    results = detector.detect(test_data)\n",
        "    print(f\"{method.value:12} (params={params}): \"\n",
        "          f\"{results.is_anomaly.sum():3} anomalies \"\n",
        "          f\"({results.anomaly_ratio:.2%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save trained model\n",
        "trainer.save_checkpoint('../models/lstm_autoencoder.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "- ‚úÖ Synthetic data generation with injected anomalies\n",
        "- ‚úÖ LSTM Autoencoder training with early stopping\n",
        "- ‚úÖ Multiple threshold methods for anomaly detection\n",
        "- ‚úÖ Comprehensive visualization of results\n",
        "\n",
        "The LSTM Autoencoder successfully learned normal patterns and detected anomalies based on reconstruction error."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
